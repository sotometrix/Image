# -*- coding: utf-8 -*-
"""REAL_Mask_RCNN_with_Detectron2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S1sZ9DYHvbzGcfMX2tb5IJWUQdH3YFaE

# Mask_RCNN with Detectron2

## Environment hardware
"""

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

"""## Install Detectron2"""

!pip install pyyaml==5.1

import torch
TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
CUDA_VERSION = torch.__version__.split("+")[-1]
print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)
# Install detectron2 that matches the above pytorch version
# See https://detectron2.readthedocs.io/tutorials/install.html for instructions
!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html
# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.

# exit(0)  # After installation, you may need to "restart runtime" in Colab. This line can also restart runtime

# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()



# import some common libraries
import numpy as np
import os, json, cv2, random
from google.colab.patches import cv2_imshow
from google.colab import files
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

from PIL import Image

import gdown
import zipfile
import shutil
import time
import functools


# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

# Setup directories
path_datasets = '/content/datasets/'
path_outputs = '/content/outputs/'

"""Download and format DAVIS Dataset"""

# Download DAVIS Dataset
os.makedirs('DAVIS/2017', exist_ok=True)


print('Downloading DAVIS 2017 trainval...')
gdown.download('https://drive.google.com/uc?id=1kiaxrX_4GuW6NmiVuKGSGVoKGWjOdp6d', output='./DAVIS/2017/DAVIS-2017-trainval-480p.zip', quiet=False)

print('Downloading DAVIS 2017 testdev...')
gdown.download('https://drive.google.com/uc?id=1fmkxU2v9cQwyb62Tj1xFDdh2p4kDsUzD', output='./DAVIS/2017/DAVIS-2017-test-dev-480p.zip', quiet=False)

print('Downloading DAVIS 2017 scribbles...')
gdown.download('https://drive.google.com/uc?id=1JzIQSu36h7dVM8q0VoE4oZJwBXvrZlkl', output='./DAVIS/2017/DAVIS-2017-scribbles-trainval.zip', quiet=False)

print('Extracting DAVIS datasets...')
with zipfile.ZipFile('./DAVIS/2017/DAVIS-2017-trainval-480p.zip', 'r') as zip_file:
    zip_file.extractall('./DAVIS/2017/')
with zipfile.ZipFile('./DAVIS/2017/DAVIS-2017-scribbles-trainval.zip', 'r') as zip_file:
    zip_file.extractall('./DAVIS/2017/')
os.rename('./DAVIS/2017/DAVIS', './DAVIS/2017/trainval')

with zipfile.ZipFile('./DAVIS/2017/DAVIS-2017-test-dev-480p.zip', 'r') as zip_file:
    zip_file.extractall('./DAVIS/2017/')
os.rename('./DAVIS/2017/DAVIS', './DAVIS/2017/test-dev')

print('Cleaning up DAVIS datasets...')
os.remove('./DAVIS/2017/DAVIS-2017-trainval-480p.zip')
os.remove('./DAVIS/2017/DAVIS-2017-test-dev-480p.zip')
os.remove('./DAVIS/2017/DAVIS-2017-scribbles-trainval.zip')

# os.getcwd()
os.mkdir('datasets')
os.mkdir('outputs')

path_D_valid_metadata = '/content/DAVIS/2017/trainval/ImageSets/2017/val.txt'
with open(path_D_valid_metadata) as f:
    validation_videos = f.readlines()
    validation_videos = [line.rstrip() for line in validation_videos]

path_images_orig = '/content/DAVIS/2017/trainval/JPEGImages/480p'
path_annot_orig = '/content/DAVIS/2017/trainval/Annotations/480p'
valid_D_directory = 'val_DAVIS_2017/'
path_D_valid = os.path.join(path_datasets, valid_D_directory)
for validation_video in validation_videos:
  shutil.copytree(
      os.path.join(path_images_orig, validation_video),
      os.path.join(path_D_valid, 'images', validation_video)
  )
  shutil.copytree(
      os.path.join(path_annot_orig, validation_video),
      os.path.join(path_D_valid, 'annot', validation_video)
  )

"""## Count annotations in categories"""

path_tot_D_valid_annot = os.path.join(path_D_valid,'annot')
path_tot_D_valid_images = os.path.join(path_D_valid,'images')

for vid in validation_videos:
  im = cv2.imread(os.path.join(path_tot_D_valid_annot, vid, '00000.png'))
  # cv2_imshow(im)
  # print(im.shape)
  # print(im[200:250,400:500])
  # print(np.unique(im.reshape(-1, 3), axis=0))
  print('Video: "{}", number of instances: {}'.format(
      vid, len(np.unique(im.reshape(-1, 3), axis=0))-1))
  # time.sleep(1)

"""## Create Detectron2 config and detectron2 predictor

# Pour LUIS !
"""

!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg
im = cv2.imread("./input.jpg")
cv2_imshow(im)

cfg = get_cfg()
# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model
# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml")
predictor = DefaultPredictor(cfg)
outputs = predictor(im)

# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification
# print(outputs["instances"].pred_classes)
# print(outputs["instances"].pred_boxes)
print(outputs["instances"].pred_masks)

# We can use `Visualizer` to draw the predictions on the image.
v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(out.get_image()[:, :, ::-1])

import functools

def applicate_mask(arr1, arr2):
  res = arr2.copy()
  res[arr1>0.] = arr1[arr1>0.]
  return res

# # Inference on DAVIS 2017 validation set
# output_D_val_dir = 'DAVIS/val'
# for vid in validation_videos:
#   for file_name in os.listdir(os.path.join(path_D_valid, vid)):
#     im = cv2.imread(os.path.join(path_D_valid, vid, file_name))
#     outputs = predictor(im)
#     segmentation_masks = outputs['instances'].pred_masks.cpu().numpy()
#     im_masks=[]
#     # for i, segmentation_mask in enumerate(segmentation_masks):
#     #   im_mask = np.zeros((*segmentation_mask.shape, 3))
#     #   im_mask[segmentation_mask] = np.array(color_palette[i])*255
#     #   # cv2_imshow(im_mask)
#     #   # time.sleep(3.)
#     #   im_masks.append(im_mask)
#     # im_mask_frame = functools.reduce(
#     #     applicate_mask,
#     #     im_masks)
#     # cv2_imshow(im_mask_frame)
#     # time.sleep(10.)
#     v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
#     out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
#     cv2_imshow(out.get_image()[:, :, ::-1])

# We just need first frame
# Inference on DAVIS 2017 validation set
output_D_val_dir = 'DAVIS/val'
for vid in validation_videos:
  print("=====================================================================")
  print('Video: {}'.format(vid))

  annot = cv2.imread(os.path.join(path_tot_D_valid_annot, vid, '00000.png'))
  nb_instances = len(np.unique(annot.reshape(-1, 3), axis=0))-1
  print(f'Number of instances: {nb_instances}')

  im = cv2.imread(os.path.join(path_tot_D_valid_images, vid, '00000.jpg'))
  outputs = predictor(im)
  segmentation_masks = outputs['instances'].pred_masks.cpu().numpy()[:nb_instances]
  im_masks=[]
  for i, segmentation_mask in enumerate(segmentation_masks):
    im_mask = np.zeros((*segmentation_mask.shape, 3))
    im_mask[segmentation_mask] = np.array(color_palette[i])*255
    im_mask.astype(int)
    cv2_imshow(im_mask)
    # time.sleep(1.)
    im_masks.append(im_mask)
  im_mask_frame = functools.reduce(
      applicate_mask,
      im_masks)
  cv2_imshow(im_mask_frame)
  # We can use `Visualizer` to draw the predictions on the image.
  v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
  out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
  cv2_imshow(out.get_image()[:, :, ::-1])
  
  input()

# Define set of videos for which there are good objects 
# but not in first position
set_poss_annot = {
    'bike-packing',
    'car-roundabout',
    'car-shadow',
    'india',
    'judo',
    'scooter-black',
    'soapbox'
}

# Define set of videos for which annotations are bad (usually missing objects)
set_bad_annot = {
    'gold-fish',
    'kite-surf',
    'lab-coat',
    'loading',
    'paragliding-launch',
    'shooting'
}

set_good_annot = set(validation_videos) - set_poss_annot - set_bad_annot

# Define color palette
palette = Image.open(os.path.join(path_tot_D_valid_annot, 'blackswan/00000.png')).getpalette()


# cf STCN repo
        # for f in range(out_masks.shape[0]):
        #     img_E = Image.fromarray(out_masks[f])
        #     print(out_masks[f].shape)
        #     # print(type(palette))
        #     # print(palette)
        #     img_E.putpalette(palette)
        #     img_E.save(os.path.join(this_out_path, '{:05d}.png'.format(f)))

# We just need first frame
# Inference on DAVIS 2017 validation set
output_D_val_dir = 'val_DAVIS_2017/annot'
path_tot_D_valid_annot_outputs = os.path.join(path_outputs, output_D_val_dir)
for vid in set_good_annot.union(set_poss_annot):
  print("=====================================================================")
  print('Video: {}'.format(vid))
  os.makedirs(os.path.join(path_tot_D_valid_annot_outputs, vid), exist_ok=True)

  annot = cv2.imread(os.path.join(path_tot_D_valid_annot, vid, '00000.png'))
  nb_instances = len(np.unique(annot.reshape(-1, 3), axis=0))-1
  print(f'Number of instances: {nb_instances}')

  im = cv2.imread(os.path.join(path_tot_D_valid_images, vid, '00000.jpg'))
  outputs = predictor(im)
  v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
  out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
  cv2_imshow(out.get_image()[:, :, ::-1])


  segmentation_masks = outputs['instances'].pred_masks.cpu().numpy()
  im_masks=[]
  count_instances = 0
  k = 0
  # print(len(segmentation_masks))
  # time.sleep(10)
  while count_instances < nb_instances and k < len(segmentation_masks):
    
    im_mask = np.zeros(segmentation_masks[k].shape)
    
    # Visualization of individual mask
    vis_mask = np.zeros((*segmentation_masks[k].shape, 3))
    vis_mask[segmentation_masks[k]] = np.array([0,0,128])
    cv2_imshow(vis_mask)
    time.sleep(3.)
    i = int(input('Label of current mask, (-1 for not present in gt): '))
    if i != -1:
      im_mask[segmentation_masks[k]] = i
      im_mask = im_mask.astype(np.uint8)
      im_masks.append(im_mask)
      count_instances += 1
    # print(np.max(im_mask))
    # cv2_imshow(im_mask)
    # time.sleep(10.)
    k += 1
  if im_masks:
    im_mask_frame = functools.reduce(
        applicate_mask,
        im_masks)
    # cv2_imshow(im_mask_frame)
    im_mask_frame = Image.fromarray(im_mask_frame)
    im_mask_frame.putpalette(palette)
    im_mask_frame.save(os.path.join(path_tot_D_valid_annot_outputs, vid, '00000.png'))
  else:
    print('no object was found in images')
  # time.sleep(10)

!zip -r /content/outputs/val_DAVIS_2017_final.zip outputs/val_DAVIS_2017/
files.download('./outputs/val_DAVIS_2017_final.zip')

# Test palette et PILLOW
im_base_via_Pillow = Image.open('/content/datasets/val_DAVIS_2017/annot/blackswan/00000.png')
im_base

im_base_via_cv2 = cv2.imread('/content/datasets/val_DAVIS_2017/annot/blackswan/00000.png')
# im_base_via_cv2

np.max(im_base_via_cv2)

im_base_via_cv2.getpalette()

temp_im = np.array(im_base_via_Pillow.convert('RGB'))
temp_im
cv2_imshow(temp_im)

# im_base_via_Pillow.getpalette()
cv2.imwrite('./outputs/test_im_palette_cv2_save.png', np.array(im_base_via_Pillow.convert('RGB')))
im_base_via_Pillow.save('./outputs/test_im_palette_pillow_save.png')

test_im_palette_cv2_save = Image.open('./outputs/test_im_palette_cv2_save.png')
test_im_palette_pillow_save = Image.open('./outputs/test_im_palette_pillow_save.png')

test_im_palette_cv2_save

test_im_palette_pillow_save

# test_im_palette_pillow_save.getpalette()
test_im_palette_cv2_save.getpalette() is None

im_test_palette_final = Image.open('/content/outputs/val_DAVIS_2017/annot/blackswan/00000.png')

im_test_palette_final

im_test_palette_final.getpalette()

